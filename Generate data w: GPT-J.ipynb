{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"execution":{"iopub.status.busy":"2023-01-17T16:10:00.117478Z","iopub.execute_input":"2023-01-17T16:10:00.118115Z","iopub.status.idle":"2023-01-17T16:10:00.122762Z","shell.execute_reply.started":"2023-01-17T16:10:00.118075Z","shell.execute_reply":"2023-01-17T16:10:00.121600Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"# !pip install -q transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-17T15:22:55.513995Z","iopub.execute_input":"2023-01-17T15:22:55.514369Z","iopub.status.idle":"2023-01-17T15:22:55.519696Z","shell.execute_reply.started":"2023-01-17T15:22:55.514335Z","shell.execute_reply":"2023-01-17T15:22:55.518640Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# !pip install -q accelerate","metadata":{"execution":{"iopub.status.busy":"2023-01-17T15:22:59.242935Z","iopub.execute_input":"2023-01-17T15:22:59.243351Z","iopub.status.idle":"2023-01-17T15:22:59.248072Z","shell.execute_reply.started":"2023-01-17T15:22:59.243314Z","shell.execute_reply":"2023-01-17T15:22:59.246900Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-01-17T15:00:15.484019Z","iopub.execute_input":"2023-01-17T15:00:15.484431Z","iopub.status.idle":"2023-01-17T15:00:17.263729Z","shell.execute_reply.started":"2023-01-17T15:00:15.484384Z","shell.execute_reply":"2023-01-17T15:00:17.262586Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import GPTJForCausalLM, AutoTokenizer\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = GPTJForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\", revision=\"float16\", low_cpu_mem_usage=True)\nmodel.to(device)\ntokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")","metadata":{"execution":{"iopub.status.busy":"2023-01-17T15:00:17.266214Z","iopub.execute_input":"2023-01-17T15:00:17.266934Z","iopub.status.idle":"2023-01-17T15:11:13.683522Z","shell.execute_reply.started":"2023-01-17T15:00:17.266887Z","shell.execute_reply":"2023-01-17T15:11:13.682311Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/836 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b47ce870917e456192d0855c411b91c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/11.3G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ab044034a5b4fcc8896dfbfdb8a6a33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/619 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"522727f3b0d9427aa6eebb64531c5075"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/779k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edd826d61e844d6b81b7a8b187a72a7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"443197bd51504f488bce9d5ad080b3bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b318461772964d0789678b2bd3769aa7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/3.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9882b8e93d90425498fe9bc2f59b22d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/357 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aa232ba51884bf7a6f1fcf3a3e2c1cd"}},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generate Prompts","metadata":{}},{"cell_type":"code","source":"data_path = \"/kaggle/input/semeval-2023-task-10/train_all_tasks.csv\"","metadata":{"execution":{"iopub.status.busy":"2023-01-17T15:22:39.979467Z","iopub.execute_input":"2023-01-17T15:22:39.980189Z","iopub.status.idle":"2023-01-17T15:22:39.984687Z","shell.execute_reply.started":"2023-01-17T15:22:39.980149Z","shell.execute_reply":"2023-01-17T15:22:39.983618Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv(data_path)\ndata = data[data[\"label_category\"]!=\"none\"]","metadata":{"execution":{"iopub.status.busy":"2023-01-17T15:22:40.424071Z","iopub.execute_input":"2023-01-17T15:22:40.424405Z","iopub.status.idle":"2023-01-17T15:22:40.574182Z","shell.execute_reply.started":"2023-01-17T15:22:40.424374Z","shell.execute_reply":"2023-01-17T15:22:40.573226Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"target_column = \"label_category\"","metadata":{"execution":{"iopub.status.busy":"2023-01-17T15:40:25.674445Z","iopub.execute_input":"2023-01-17T15:40:25.675182Z","iopub.status.idle":"2023-01-17T15:40:25.679817Z","shell.execute_reply.started":"2023-01-17T15:40:25.675138Z","shell.execute_reply":"2023-01-17T15:40:25.678698Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"label_category_map = {\n    \"1. threats, plans to harm and incitement\":\"Threat\",\n    \"2. derogation\":\"Derogation\",\n    \"3. animosity\":\"Animosity\",\n    \"4. prejudiced discussions\":\"Prejudiced discussion\",\n    \"Threat\":\"1. threats, plans to harm and incitement\",\n    \"Derogation\":\"2. derogation\",\n    \"Animosity\":\"3. animosity\",\n    \"Prejudiced discussion\":\"4. prejudiced discussions\"\n}","metadata":{"execution":{"iopub.status.busy":"2023-01-17T15:23:06.112413Z","iopub.execute_input":"2023-01-17T15:23:06.112856Z","iopub.status.idle":"2023-01-17T15:23:06.119225Z","shell.execute_reply.started":"2023-01-17T15:23:06.112818Z","shell.execute_reply":"2023-01-17T15:23:06.117849Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"labels = data[target_column].unique()\nlabels","metadata":{"execution":{"iopub.status.busy":"2023-01-17T15:41:03.667317Z","iopub.execute_input":"2023-01-17T15:41:03.667749Z","iopub.status.idle":"2023-01-17T15:41:03.676845Z","shell.execute_reply.started":"2023-01-17T15:41:03.667710Z","shell.execute_reply":"2023-01-17T15:41:03.675703Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"array(['2. derogation', '1. threats, plans to harm and incitement',\n       '3. animosity', '4. prejudiced discussions'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"import random\n# function returns two random text samples to use them as GPT-J prompt\n# def get_three_random_samples(data_frame, target_column):\n#     # get two random samples from `data file`\n#     s1, s2, s3 = random.sample(range(0, len(data)), 3)\n\n#     # get text labels\n#     d = data_frame.iloc[[s1, s2, s3]]\n#     return list(zip(d['text'].values, d[target_column].values))\n\ndef get_three_random_samples(data_frame, target_column, label, n=3):\n    # get two random samples from `data file`\n    \n    d = data_frame[data_frame[target_column]==label]\n    s1, s2, s3 = random.sample(range(0, len(d)), n)\n\n    # get text labels\n    d = d.iloc[[s1, s2, s3]]\n    return list(zip(d['text'].values, d[target_column].values))\n\nsamples = get_three_random_samples(data, target_column, labels[0])","metadata":{"execution":{"iopub.status.busy":"2023-01-17T15:42:24.305523Z","iopub.execute_input":"2023-01-17T15:42:24.306655Z","iopub.status.idle":"2023-01-17T15:42:24.316764Z","shell.execute_reply.started":"2023-01-17T15:42:24.306611Z","shell.execute_reply":"2023-01-17T15:42:24.315634Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def get_prompt(samples):\n#     # define a function that takes as input three samples and generates the prompt\n#     # that we should pass to the GPT-3 language model for completion.\n#     description = \"Each item in the following list contains a sexist tweet and the respective category. Category is one of 'Threat', 'Derogation', 'Animosity', or 'Prejudiced discussion'\"\n    \n#     prompt = f\"{description}\\n\"\n#     for text, label in samples:\n#         prompt += f\"Tweet: {text} (Sentiment: {label_category_map[label]})\\n\"\n    \n#     return prompt\n\ndef get_prompt(samples, label):\n    prompt = f\"These are examples of {label_category_map[label]} tweets:\\n\"\n    for text, label in samples:\n        prompt += f\"* {text}\\n\"\n    \n    return prompt\n\nprompt = get_prompt(samples, labels[0])\nprint(prompt)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T15:45:02.525410Z","iopub.execute_input":"2023-01-17T15:45:02.526738Z","iopub.status.idle":"2023-01-17T15:45:02.535484Z","shell.execute_reply.started":"2023-01-17T15:45:02.526685Z","shell.execute_reply":"2023-01-17T15:45:02.534209Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"These are examples of Derogation tweets:\n* All of those SJW purple haired foids over IT have 5'2\" balding curry janitor bfs and that's a fact.\n* Women only,girls only. Imagine if it was Men only. They be crying oppression and anti wymyn. Just cunts being cunts. This are the types where you just ignore them and act like they don't even exists. Too bad for this guy.\n* Ive spent time in Sydney. They have legal prostitution there so the women have to be slightly less cunty to compete with the professionals. Its better than the west.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"def generate_text(prompt):\n    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n\n    generated_ids = model.generate(input_ids, do_sample=True, temperature=0.9, max_length=500)\n    generated_text = tokenizer.decode(generated_ids[0])\n    return generated_text\n\nnew_text = generate_text(prompt)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T15:45:14.455892Z","iopub.execute_input":"2023-01-17T15:45:14.456443Z","iopub.status.idle":"2023-01-17T15:46:04.657085Z","shell.execute_reply.started":"2023-01-17T15:45:14.456404Z","shell.execute_reply":"2023-01-17T15:46:04.655841Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(prompt)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T15:46:04.658903Z","iopub.execute_input":"2023-01-17T15:46:04.659255Z","iopub.status.idle":"2023-01-17T15:46:04.666431Z","shell.execute_reply.started":"2023-01-17T15:46:04.659218Z","shell.execute_reply":"2023-01-17T15:46:04.665228Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"These are examples of Derogation tweets:\n* All of those SJW purple haired foids over IT have 5'2\" balding curry janitor bfs and that's a fact.\n* Women only,girls only. Imagine if it was Men only. They be crying oppression and anti wymyn. Just cunts being cunts. This are the types where you just ignore them and act like they don't even exists. Too bad for this guy.\n* Ive spent time in Sydney. They have legal prostitution there so the women have to be slightly less cunty to compete with the professionals. Its better than the west.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"prompts = [\n    get_prompt(samples, labels[0]),\n    get_prompt(samples, labels[0])\n]","metadata":{"execution":{"iopub.status.busy":"2023-01-17T15:50:29.027400Z","iopub.execute_input":"2023-01-17T15:50:29.027823Z","iopub.status.idle":"2023-01-17T15:50:29.033076Z","shell.execute_reply.started":"2023-01-17T15:50:29.027788Z","shell.execute_reply":"2023-01-17T15:50:29.031969Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"tokenizer.padding_side = \"left\"\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2023-01-17T15:51:23.260847Z","iopub.execute_input":"2023-01-17T15:51:23.261279Z","iopub.status.idle":"2023-01-17T15:51:23.267322Z","shell.execute_reply.started":"2023-01-17T15:51:23.261247Z","shell.execute_reply":"2023-01-17T15:51:23.265819Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"def generate_text_in_batch(prompts):\n    encoding = tokenizer(prompts, padding=True, return_tensors='pt').to(device)\n    with torch.no_grad():\n        generated_ids = model.generate(**encoding, do_sample=True, temperature=0.9, max_length=300, pad_token_id=tokenizer.eos_token_id)\n    generated_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n    \n    return generated_texts\n\ngenerated_texts = generate_text_in_batch(prompts)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T16:06:08.879973Z","iopub.execute_input":"2023-01-17T16:06:08.880343Z","iopub.status.idle":"2023-01-17T16:06:25.370574Z","shell.execute_reply.started":"2023-01-17T16:06:08.880311Z","shell.execute_reply":"2023-01-17T16:06:25.369605Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport json\n\ntexts = {}\n\nnbatch = 2500\nbatch_size = 4\n\nfor label in labels:\n    texts[label] = []\n    \n    \nfor i in tqdm(range(nbatch), total=nbatch):\n    for label in labels:\n        prompts = []\n        for b in range(batch_size):\n            prompts.append(get_prompt(samples, label))\n        generated_texts = generate_text_in_batch(prompts)\n        texts[label].append(generated_texts)\n    \n    if i%10==0 and i!=0:\n        with open(f'gpt_generated_texts_{i}.json', 'w') as outfile:\n            json.dump(texts, outfile)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-17T16:20:51.384869Z","iopub.execute_input":"2023-01-17T16:20:51.385240Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  6%|â–‹         | 159/2500 [2:53:57<42:37:33, 65.55s/it]","output_type":"stream"}]},{"cell_type":"code","source":"\"DONE\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-01-17T16:05:58.066586Z","iopub.status.idle":"2023-01-17T16:05:58.068004Z","shell.execute_reply.started":"2023-01-17T16:05:58.067699Z","shell.execute_reply":"2023-01-17T16:05:58.067727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}