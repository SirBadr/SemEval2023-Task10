{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2244,"status":"ok","timestamp":1675386076829,"user":{"displayName":"Pakawat Nakwijit","userId":"01430675152978466058"},"user_tz":0},"id":"sHyS00BLlWd6","outputId":"4fcda3c6-ffa8-42d6-e01f-35e0cdc44b06"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1675386076829,"user":{"displayName":"Pakawat Nakwijit","userId":"01430675152978466058"},"user_tz":0},"id":"vd0eo8cegRT8","outputId":"c026fe76-5e1e-45fe-cd63-13810d4d0aa4"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/.shortcut-targets-by-id/1lC-ZKLaCDQyfLcof2Ak7FDa6IvTt318A/SemEval2023/SemEval2022-Task10/re_run\n"]}],"source":["cd /content/gdrive/MyDrive/SemEval2023/SemEval2022-Task10/re_run"]},{"cell_type":"code","source":[],"metadata":{"id":"-40XIl5Hz8zy"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mcg-u_-QghEO"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","source":[],"metadata":{"id":"DpYnTvGWRidT"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KxVljKIpjonw"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","target_column = \"label_vector\"\n","data = pd.read_csv(\"../Data/starting_ki/train_all_tasks.csv\")\n","\n","# target_column = \"label_vector\"\n","# data = pd.read_csv(\"../GeneratedTexts/task_c_generated_text.csv\")\n","# data[target_column] = data[\"label\"]\n","\n","data = data[data[target_column]!=\"none\"]\n","data.reset_index(inplace=True)\n","data.drop(columns=['index'], inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7MroRLHpw9xL"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g6Hq_qExqg3g","colab":{"base_uri":"https://localhost:8080/","height":426},"executionInfo":{"status":"ok","timestamp":1675386088316,"user_tz":0,"elapsed":6,"user":{"displayName":"Pakawat Nakwijit","userId":"01430675152978466058"}},"outputId":"0e61578b-ffd2-4a52-f15d-2030c2905552"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                    rewire_id  text  \\\n","label_vector                                                          \n","1.1 threats of harm                                        56    56   \n","1.2 incitement and encouragement of harm                  254   254   \n","2.1 descriptive attacks                                   717   717   \n","2.2 aggressive and emotive attacks                        673   673   \n","2.3 dehumanising attacks & overt sexual objecti...        200   200   \n","3.1 casual use of gendered slurs, profanities, ...        637   637   \n","3.2 immutable gender differences and gender ste...        417   417   \n","3.3 backhanded gendered compliments                        64    64   \n","3.4 condescending explanations or unwelcome advice         47    47   \n","4.1 supporting mistreatment of individual women            75    75   \n","4.2 supporting systemic discrimination against ...        258   258   \n","\n","                                                    label_sexist  \\\n","label_vector                                                       \n","1.1 threats of harm                                           56   \n","1.2 incitement and encouragement of harm                     254   \n","2.1 descriptive attacks                                      717   \n","2.2 aggressive and emotive attacks                           673   \n","2.3 dehumanising attacks & overt sexual objecti...           200   \n","3.1 casual use of gendered slurs, profanities, ...           637   \n","3.2 immutable gender differences and gender ste...           417   \n","3.3 backhanded gendered compliments                           64   \n","3.4 condescending explanations or unwelcome advice            47   \n","4.1 supporting mistreatment of individual women               75   \n","4.2 supporting systemic discrimination against ...           258   \n","\n","                                                    label_category  \n","label_vector                                                        \n","1.1 threats of harm                                             56  \n","1.2 incitement and encouragement of harm                       254  \n","2.1 descriptive attacks                                        717  \n","2.2 aggressive and emotive attacks                             673  \n","2.3 dehumanising attacks & overt sexual objecti...             200  \n","3.1 casual use of gendered slurs, profanities, ...             637  \n","3.2 immutable gender differences and gender ste...             417  \n","3.3 backhanded gendered compliments                             64  \n","3.4 condescending explanations or unwelcome advice              47  \n","4.1 supporting mistreatment of individual women                 75  \n","4.2 supporting systemic discrimination against ...             258  "],"text/html":["\n","  <div id=\"df-c3af8dcb-04ff-477f-97dd-3cba0dad3653\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>rewire_id</th>\n","      <th>text</th>\n","      <th>label_sexist</th>\n","      <th>label_category</th>\n","    </tr>\n","    <tr>\n","      <th>label_vector</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1.1 threats of harm</th>\n","      <td>56</td>\n","      <td>56</td>\n","      <td>56</td>\n","      <td>56</td>\n","    </tr>\n","    <tr>\n","      <th>1.2 incitement and encouragement of harm</th>\n","      <td>254</td>\n","      <td>254</td>\n","      <td>254</td>\n","      <td>254</td>\n","    </tr>\n","    <tr>\n","      <th>2.1 descriptive attacks</th>\n","      <td>717</td>\n","      <td>717</td>\n","      <td>717</td>\n","      <td>717</td>\n","    </tr>\n","    <tr>\n","      <th>2.2 aggressive and emotive attacks</th>\n","      <td>673</td>\n","      <td>673</td>\n","      <td>673</td>\n","      <td>673</td>\n","    </tr>\n","    <tr>\n","      <th>2.3 dehumanising attacks &amp; overt sexual objectification</th>\n","      <td>200</td>\n","      <td>200</td>\n","      <td>200</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>3.1 casual use of gendered slurs, profanities, and insults</th>\n","      <td>637</td>\n","      <td>637</td>\n","      <td>637</td>\n","      <td>637</td>\n","    </tr>\n","    <tr>\n","      <th>3.2 immutable gender differences and gender stereotypes</th>\n","      <td>417</td>\n","      <td>417</td>\n","      <td>417</td>\n","      <td>417</td>\n","    </tr>\n","    <tr>\n","      <th>3.3 backhanded gendered compliments</th>\n","      <td>64</td>\n","      <td>64</td>\n","      <td>64</td>\n","      <td>64</td>\n","    </tr>\n","    <tr>\n","      <th>3.4 condescending explanations or unwelcome advice</th>\n","      <td>47</td>\n","      <td>47</td>\n","      <td>47</td>\n","      <td>47</td>\n","    </tr>\n","    <tr>\n","      <th>4.1 supporting mistreatment of individual women</th>\n","      <td>75</td>\n","      <td>75</td>\n","      <td>75</td>\n","      <td>75</td>\n","    </tr>\n","    <tr>\n","      <th>4.2 supporting systemic discrimination against women as a group</th>\n","      <td>258</td>\n","      <td>258</td>\n","      <td>258</td>\n","      <td>258</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3af8dcb-04ff-477f-97dd-3cba0dad3653')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c3af8dcb-04ff-477f-97dd-3cba0dad3653 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c3af8dcb-04ff-477f-97dd-3cba0dad3653');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["data.groupby(target_column).count()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KMhjlSKfsLbV"},"outputs":[],"source":["if target_column == \"label_category\":\n","  label_values = [\n","      '1. threats, plans to harm and incitement',\n","      '2. derogation',\n","      '3. animosity',\n","      '4. prejudiced discussions',\n","  ]\n","\n","elif target_column == \"label_vector\":\n","  label_values = [\n","      '1.1 threats of harm',\n","      '1.2 incitement and encouragement of harm',\n","      '2.1 descriptive attacks',\n","      '2.2 aggressive and emotive attacks',\n","      '2.3 dehumanising attacks & overt sexual objectification',\n","      '3.1 casual use of gendered slurs, profanities, and insults',\n","      '3.2 immutable gender differences and gender stereotypes',\n","      '3.3 backhanded gendered compliments',\n","      '3.4 condescending explanations or unwelcome advice',\n","      '4.1 supporting mistreatment of individual women',\n","      '4.2 supporting systemic discrimination against women as a group',\n","  ]"]},{"cell_type":"markdown","metadata":{"id":"S4LEXa0LTwbj"},"source":["## Calculate Shapley"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hNKX-daoT0sc"},"outputs":[],"source":["!pip install -q transformers shap"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QiUYmNhwT4IQ"},"outputs":[],"source":["from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"]},{"cell_type":"code","source":["ls Models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Va9tL3FRNrHd","executionInfo":{"status":"ok","timestamp":1675386102675,"user_tz":0,"elapsed":11,"user":{"displayName":"Pakawat Nakwijit","userId":"01430675152978466058"}},"outputId":"12e17cc4-43cb-43a7-87f4-9571b5799ace"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mfine-tuned-bert\u001b[0m/  \u001b[01;34mfine-tuned-bertweet\u001b[0m/  \u001b[01;34mfine-tuned-twhinbert\u001b[0m/\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SBrnlO3pUDgj"},"outputs":[],"source":["import torch\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","out_dir = f'Models/fine-tuned-bert'\n","model = BertForSequenceClassification.from_pretrained(out_dir)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bDGUbw-CTlYf"},"outputs":[],"source":["import transformers\n","import torch\n","import numpy as np\n","import scipy as sp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D6L0tWLQUZoH"},"outputs":[],"source":["texts = data['text'].values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5v03chzpTlbH"},"outputs":[],"source":["import shap\n","# define a prediction function\n","def f(texts):\n","  text_ids = [tokenizer.encode(text, max_length=100, padding='max_length', truncation=True) for text in texts]\n","\n","  att_masks = []\n","  for ids in text_ids:\n","      masks = [int(id > 0) for id in ids]\n","      att_masks.append(masks)\n","\n","  text_ids = torch.tensor(text_ids).to(device)\n","  att_masks = torch.tensor(att_masks).to(device)\n","\n","  outputs = model(text_ids, attention_mask=att_masks)\n","  outputs = outputs[0].detach().cpu().numpy()\n","  scores = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n","  \n","  val = sp.special.logit(scores[:,1]) # use one vs rest logit units\n","  return val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xM6Vf6wWYDSq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675386117519,"user_tz":0,"elapsed":6,"user":{"displayName":"Pakawat Nakwijit","userId":"01430675152978466058"}},"outputId":"3d837457-9342-43c0-d893-53fc81770f6a"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.1 threats of harm\n","1.2 incitement and encouragement of harm\n","2.1 descriptive attacks\n","2.2 aggressive and emotive attacks\n","2.3 dehumanising attacks & overt sexual objectification\n","3.1 casual use of gendered slurs, profanities, and insults\n","3.2 immutable gender differences and gender stereotypes\n","3.3 backhanded gendered compliments\n","3.4 condescending explanations or unwelcome advice\n","4.1 supporting mistreatment of individual women\n","4.2 supporting systemic discrimination against women as a group\n"]}],"source":["for label in label_values:\n","  print(label)"]},{"cell_type":"code","source":[],"metadata":{"id":"EtFUmTeFshPX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1oZDhfaeYZt2"},"outputs":[],"source":["# import pickle\n","\n","# def save_shap_values(filepath, obj):\n","#   with open(filepath, 'wb') as fin:\n","#     pickle.dump(obj, fin)\n","    \n","\n","# explainer = shap.Explainer(f, tokenizer)\n","\n","# d = data\n","# d = {\"text\": d[\"text\"].values}\n","# shap_values = explainer(d, fixed_context=1, batch_size=256)\n","# save_shap_values(f\"./Results/shapley_values.pickle\", shap_values)"]},{"cell_type":"code","source":["import pickle\n","\n","def load_shap_values(filepath):\n","  with open(filepath, 'rb') as fin:\n","    obj = pickle.load(fin)\n","  return obj\n","\n","shap_values = load_shap_values(f\"./Results/shapley_values.pickle\")"],"metadata":{"id":"580ZvNNJPeX_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uDYNYsa2zPei"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_lexicons(train, shap_values):\n","  lexicons = {}\n","  for idx, label in enumerate(label_values):\n","    d = train[train[target_column]==label]\n","    d = data.reset_index().merge(d[[\"rewire_id\"]], on=\"rewire_id\").set_index('index')\n","    s = shap_values.abs[d.index.to_numpy()]\n","\n","    feature_names = s.mean(0).feature_names\n","    shapley_values = s.mean(0).values\n","\n","    sorted_values = sorted(zip(shapley_values, feature_names), key=lambda pair: -pair[0])\n","    lexicons[label] = {x:v for v, x in sorted_values}\n","  return lexicons\n","  \n","# train = pd.read_csv(f\"Data/0_train.csv\")\n","# lexicons = get_lexicons(train, shap_values)"],"metadata":{"id":"p4ZeLMbaW8fg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PnnRpGI-W8iV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for k in lexicons:\n","#   for sw in lexicons[k]:\n","#     if sw.startswith(\"#\") or sw.startswith(\"_\"):\n","#       print(sw)\n","#     if sw.endswith(\"#\") or sw.endswith(\"_\"):\n","#       print(sw)"],"metadata":{"id":"BuI8hsHTW8lM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZYJsKprEtwf_"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# Handle subwords"],"metadata":{"id":"jTxTc7NJyp_f"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')"],"metadata":{"id":"JLzzyV46yszN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675386150689,"user_tz":0,"elapsed":348,"user":{"displayName":"Pakawat Nakwijit","userId":"01430675152978466058"}},"outputId":"afc545a6-2bf0-4079-8e48-13355ceb6572"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["from nltk.tokenize import TweetTokenizer\n","nltktokenizer = TweetTokenizer()\n","\n","def word_tokenize(sent):\n","  # return nltk.word_tokenize(sent)\n","  return nltktokenizer.tokenize(sent)"],"metadata":{"id":"SYFCwpHZzMhK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import defaultdict\n","\n","def map_subwords(words, subwords):\n","  sidx = 0\n","  widx = 0\n","  w = \"\"\n","  mapping = []\n","\n","  while widx < len(words):\n","    w = w + words[widx]\n","    if sidx >= len(subwords):\n","      print(widx, w, sidx)\n","      print(words)\n","      print(subwords)\n","\n","    idx = [sidx]\n","    s = subwords[sidx].replace(\"#\", \"\")\n","\n","    while len(w) < len(s):\n","      widx += 1\n","      w = w + words[widx].strip()\n","\n","    # if words[0] == \"thotlife\":\n","    #     print(w, s)\n","\n","    while s!=w and len(s) < len(w) and sidx+1 < len(subwords):\n","      sidx += 1\n","      s += subwords[sidx].replace(\"#\", \"\").strip()\n","      idx.append(sidx)\n","\n","      # if words[0] == \"thotlife\":\n","      #   print(f\"[{w}] [{s}]\", len(w), len(s), w==s)\n","\n","    if len(s) > len(w):\n","      widx += 1\n","      sidx -= len(idx) - 1\n","      continue\n","    \n","  \n","    if len(w) > 20 and w not in words:\n","      print(\"ERROR\", w)\n","\n","      # assert(False)    \n","    sidx += 1\n","    # print(w, s, idx)\n","    widx += 1\n","    w = \"\"\n","\n","    mapping.append(idx)\n","\n","  return mapping\n","\n","def normalise_quote(tokens):\n","  for widx, w in enumerate(tokens):\n","    if w==\"``\":\n","      tokens[widx] = '\"'\n","    elif w==\"''\":\n","      tokens[widx] = '\"'\n","    elif w==\"... ...\":\n","      tokens[widx] = '......'\n","      \n","  return tokens\n","\n","\n"],"metadata":{"id":"fYRqFHXCyrSZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from itertools import groupby\n","def clean_and_tokenize(sent):\n","  sent = sent.lower().replace(\"#\", \"\").replace(\"''\", '\"').replace(\".\", \" \").replace(\"-\", \" \").replace(\"&x200b;\", \"\")\n","\n","  # remove more than 3 consecutive repeated characters\n","  groups = groupby(sent)\n","  sent = \"\".join([label*min(3, sum(1 for _ in group)) for label, group in groups])\n","  \n","\n","  sent = sent.encode(\"ascii\", \"ignore\")\n","  sent = sent.decode()\n","  \n","  words = word_tokenize(sent)\n","  words = normalise_quote(words)\n","    \n","  subwords = swtokenizer.tokenize(sent)\n","  subwords = normalise_quote(subwords)\n","  return words, subwords\n","\n","def merge_score(new_lexicons, idxs, subwords):\n","  for idx in idxs:\n","    w = \"\"\n","    s = 0\n","    for i in idx:\n","      sw = subwords[i].replace(\"#\", \"\")\n","      w += sw\n","      if sw not in lexicons[label]:\n","      #   print(\">>\", sw)\n","        continue\n","\n","      s += lexicons[label][sw]\n","      \n","    new_lexicons[w] = max(new_lexicons[w], s)\n","  return new_lexicons"],"metadata":{"id":"1kd_2T2sHyKt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def merge_subwords(lexicons, train):\n","  vocabs = {}\n","  new_lexicons_scores = {}\n","\n","  for idx, label in enumerate(label_values):\n","    print(\"Working on\", label)\n","    new_lexicons = defaultdict(int)\n","\n","    d = train[train[target_column]==label]\n","    texts = d[\"text\"].values\n","\n","    for sent in texts:\n","      words, subwords = clean_and_tokenize(sent)\n","      idxs = map_subwords(words, subwords)\n","      new_lexicons = merge_score(new_lexicons, idxs, subwords)\n","  \n","    sorted_list = sorted(new_lexicons.items(), key=lambda item: -item[1])\n","    new_lexicons_scores[label] = { k:v for k, v in sorted_list if v > 0}\n","  return new_lexicons_scores\n","\n","# newlexicons = merge_subwords(lexicons, train)\n","# for c in newlexicons:\n","#   newlexicons[c] = {k: v for k, v in sorted(newlexicons[c].items(), key=lambda item: -item[1])}\n","\n","#   print(c, list(newlexicons[c].keys())[0:10])"],"metadata":{"id":"zMiN9eqmH2Ft"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"--NIelJ-H2Le"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qGCIbLLvH2TP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","def filter_lexicons(lexicons, q=0.8):\n","  threshold = {}\n","  for l in lexicons:\n","    values = [v for k, v in lexicons[l].items()]\n","    threshold[l] = np.quantile(values, q)\n","\n","\n","  new_lexicons = {}\n","  for l in lexicons:\n","    new_lexicons[l] = {}\n","    for w in lexicons[l]:\n","      v = lexicons[l][w]\n","\n","      if v > threshold[l]:\n","        new_lexicons[l][w] = v\n","  return new_lexicons\n","\n","# filtered_lexicons = filter_lexicons(newlexicons, q=0.8)"],"metadata":{"id":"B1cILFs0DvgU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xsVOp8MQAhIP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Mqr2RKSFBJV2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VZJ0vzY9AjqH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bd5SleWYCnz0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-ZSY1v_OC1cf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluation"],"metadata":{"id":"GvUkpppJgH5M"}},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","\n","def predict(word, lexicons):\n","  cnt = {}\n","  for label in label_values:\n","    cnt[label] = 0\n","\n","  for w in word:\n","    for label in label_values:\n","      if w in lexicons[label]:\n","        cnt[label] += lexicons[label][w]\n","\n","  \n","  if sum(cnt.values())==0:\n","    return None\n","  \n","  return max(cnt.items(), key=lambda k: k[1])[0]\n","\n","def run_predict(test_words, test_labels, lexicons, return_predict=False):\n","  y_pred = []\n","  y_test = []\n","  non = 0\n","  for word, label in zip(test_words, test_labels):\n","    pred = predict(word, lexicons)\n","    if pred is None:\n","      non += 1\n","      continue\n","\n","    y_pred.append(pred)\n","    y_test.append(label)\n","\n","  f1 = f1_score(y_test, y_pred, average='macro')\n","  skip = non/len(test_words)\n","\n","  if return_predict:\n","    return f1, skip, y_test, y_pred\n","    \n","  return f1, skip\n","\n","# test = pd.read_csv(f\"Data/0_test.csv\")\n","# test_words = [nltk.word_tokenize(sent) for sent in test[\"text\"].values]\n","# test_labels = test[target_column].values\n","\n","# run_predict(test_words, test_labels, filtered_lexicons)"],"metadata":{"id":"5R1wQL68gMWo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"q3mrxCuLgN8Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Hypterparameter Tuning"],"metadata":{"id":"bLCzcOcQhHjV"}},{"cell_type":"code","source":["all_f1, all_skip = {}, {}\n","for q in np.arange(0.5, 1, 0.05):\n","  all_f1[q] = []\n","  all_skip[q] = []"],"metadata":{"id":"oJqnWRR6hJX_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(5):\n","  train = pd.read_csv(f\"Data/{i}_train.csv\")\n","\n","  val = pd.read_csv(f\"Data/{i}_val.csv\")\n","  val_words = [word_tokenize(sent) for sent in val[\"text\"].values]\n","  val_labels = val[target_column].values\n","\n","  lexicons = get_lexicons(train, shap_values)\n","  newlexicons = merge_subwords(lexicons, train)\n","  \n","\n","  for q in np.arange(0.5, 1, 0.05):\n","    filtered_lexicons = filter_lexicons(newlexicons, q=q)\n","    f1, skip = run_predict(val_words, val_labels, filtered_lexicons)\n","\n","    all_f1[q].append(f1)\n","    all_skip[q].append(skip)\n","\n","  print(\"DONE\",i)\n","  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93MSTFr4hOwA","executionInfo":{"status":"ok","timestamp":1675386215311,"user_tz":0,"elapsed":44724,"user":{"displayName":"Pakawat Nakwijit","userId":"01430675152978466058"}},"outputId":"ab807620-8873-4c38-c09d-bec60a472e82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"output_type":"stream","name":"stdout","text":["Working on 1.1 threats of harm\n","Working on 1.2 incitement and encouragement of harm\n","Working on 2.1 descriptive attacks\n","Working on 2.2 aggressive and emotive attacks\n","Working on 2.3 dehumanising attacks & overt sexual objectification\n","Working on 3.1 casual use of gendered slurs, profanities, and insults\n","Working on 3.2 immutable gender differences and gender stereotypes\n","Working on 3.3 backhanded gendered compliments\n","Working on 3.4 condescending explanations or unwelcome advice\n","Working on 4.1 supporting mistreatment of individual women\n","Working on 4.2 supporting systemic discrimination against women as a group\n","DONE 0\n"]},{"output_type":"stream","name":"stderr","text":["Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"output_type":"stream","name":"stdout","text":["Working on 1.1 threats of harm\n","Working on 1.2 incitement and encouragement of harm\n","Working on 2.1 descriptive attacks\n","Working on 2.2 aggressive and emotive attacks\n","Working on 2.3 dehumanising attacks & overt sexual objectification\n","Working on 3.1 casual use of gendered slurs, profanities, and insults\n","Working on 3.2 immutable gender differences and gender stereotypes\n","Working on 3.3 backhanded gendered compliments\n","Working on 3.4 condescending explanations or unwelcome advice\n","Working on 4.1 supporting mistreatment of individual women\n","Working on 4.2 supporting systemic discrimination against women as a group\n","DONE 1\n"]},{"output_type":"stream","name":"stderr","text":["Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"output_type":"stream","name":"stdout","text":["Working on 1.1 threats of harm\n","Working on 1.2 incitement and encouragement of harm\n","Working on 2.1 descriptive attacks\n","Working on 2.2 aggressive and emotive attacks\n","Working on 2.3 dehumanising attacks & overt sexual objectification\n","Working on 3.1 casual use of gendered slurs, profanities, and insults\n","Working on 3.2 immutable gender differences and gender stereotypes\n","Working on 3.3 backhanded gendered compliments\n","Working on 3.4 condescending explanations or unwelcome advice\n","Working on 4.1 supporting mistreatment of individual women\n","Working on 4.2 supporting systemic discrimination against women as a group\n","DONE 2\n"]},{"output_type":"stream","name":"stderr","text":["Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"output_type":"stream","name":"stdout","text":["Working on 1.1 threats of harm\n","Working on 1.2 incitement and encouragement of harm\n","Working on 2.1 descriptive attacks\n","Working on 2.2 aggressive and emotive attacks\n","Working on 2.3 dehumanising attacks & overt sexual objectification\n","Working on 3.1 casual use of gendered slurs, profanities, and insults\n","Working on 3.2 immutable gender differences and gender stereotypes\n","Working on 3.3 backhanded gendered compliments\n","Working on 3.4 condescending explanations or unwelcome advice\n","Working on 4.1 supporting mistreatment of individual women\n","Working on 4.2 supporting systemic discrimination against women as a group\n","DONE 3\n"]},{"output_type":"stream","name":"stderr","text":["Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"output_type":"stream","name":"stdout","text":["Working on 1.1 threats of harm\n","Working on 1.2 incitement and encouragement of harm\n","Working on 2.1 descriptive attacks\n","Working on 2.2 aggressive and emotive attacks\n","Working on 2.3 dehumanising attacks & overt sexual objectification\n","Working on 3.1 casual use of gendered slurs, profanities, and insults\n","Working on 3.2 immutable gender differences and gender stereotypes\n","Working on 3.3 backhanded gendered compliments\n","Working on 3.4 condescending explanations or unwelcome advice\n","Working on 4.1 supporting mistreatment of individual women\n","Working on 4.2 supporting systemic discrimination against women as a group\n","DONE 4\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","for q in np.arange(0.5, 1, 0.05):\n","  print(f\"{q:.3f} >> F1:{np.mean(all_f1[q]):.3f}±{np.std(all_f1[q]):.3f}, SKIP: {np.mean(all_skip[q]):.3f}±{np.std(all_skip[q]):.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yrZzM_BCh7oQ","executionInfo":{"status":"ok","timestamp":1675386221646,"user_tz":0,"elapsed":410,"user":{"displayName":"Pakawat Nakwijit","userId":"01430675152978466058"}},"outputId":"80a0d383-87c6-48bc-8060-503060fa9530"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.500 >> F1:0.139±0.018, SKIP: 0.000±0.000\n","0.550 >> F1:0.139±0.026, SKIP: 0.000±0.000\n","0.600 >> F1:0.139±0.025, SKIP: 0.001±0.001\n","0.650 >> F1:0.129±0.028, SKIP: 0.001±0.002\n","0.700 >> F1:0.127±0.025, SKIP: 0.002±0.002\n","0.750 >> F1:0.118±0.027, SKIP: 0.002±0.002\n","0.800 >> F1:0.124±0.031, SKIP: 0.005±0.003\n","0.850 >> F1:0.120±0.029, SKIP: 0.012±0.007\n","0.900 >> F1:0.124±0.026, SKIP: 0.043±0.007\n","0.950 >> F1:0.120±0.027, SKIP: 0.118±0.017\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"6umdIiZKh-67"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for k in lexicons:\n","  print(k, list(lexicons[k])[0:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jUKMBRKrikXb","executionInfo":{"status":"ok","timestamp":1675386253607,"user_tz":0,"elapsed":295,"user":{"displayName":"Pakawat Nakwijit","userId":"01430675152978466058"}},"outputId":"5a975bad-c8b8-4df3-cfdd-8433920fbf11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1.1 threats of harm ['whore', 'bitch', 'pussy', 'women', 'guaranteed', 'penis', 'sex', 'girls', 'leo', 'those']\n","1.2 incitement and encouragement of harm ['whore', 'pussy', 'bitch', 'ska', 'feminism', 'ssi', 'pork', 'feminist', 'prostitutes', 'ars']\n","2.1 descriptive attacks ['ska', 'bitch', 'ssi', 'oids', 'prostitute', 'bravo', 'ji', 'rejection', 'hurting', 'azi']\n","2.2 aggressive and emotive attacks ['isa', 'bitch', 'dyke', 'hooker', 'odle', 'ards', 'whore', 'handles', 'ricky', 'thug']\n","2.3 dehumanising attacks & overt sexual objectification ['bitch', 'whore', 'hooker', 'pussy', 'odle', 'ho', 'lays', 'ssi', 'chick', 'prostitute']\n","3.1 casual use of gendered slurs, profanities, and insults ['bitch', 'pussy', 'auto', 'whore', 'dyke', 'pizza', 'mode', 'ssi', 'ho', 'pu']\n","3.2 immutable gender differences and gender stereotypes ['bitch', 'daughters', 'hooker', 'perfect', 'lady', 'babe', 'mom', 'bra', 'clit', 'chicks']\n","3.3 backhanded gendered compliments ['bitch', 'dyke', 'pussy', 'sl', 'females', 'sensible', 'blonde', 'look', 'gal', 'ut']\n","3.4 condescending explanations or unwelcome advice ['girls', 'pussy', 'ladies', 'wife', 'bitch', 'mom', 'female', 'different', 'jesus', 'lady']\n","4.1 supporting mistreatment of individual women ['whore', 'fe', 'feminist', 'pussy', 'regretted', 'idiots', 'ac', 'mina', 'body', 'pu']\n","4.2 supporting systemic discrimination against women as a group ['pussy', 'mothers', 'linda', 'fe', 'sub', 'sar', 'companies', 'debates', 'feminine', 'irony']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Z7QHAWw2ikax"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluate Lexicons"],"metadata":{"id":"JWHWkhX9ikil"}},{"cell_type":"code","source":["from sklearn.metrics import precision_recall_fscore_support\n","import json\n","\n","all_f1 = []\n","all_skip = []\n","all_p = []\n","all_r = []\n","\n","for i in range(5):\n","  train = pd.read_csv(f\"Data/{i}_train.csv\")\n","  test = pd.read_csv(f\"Data/{i}_test.csv\")\n","\n","  texts = test[\"text\"].values\n","  test_words = [word_tokenize(sent) for sent in test[\"text\"].values]\n","  test_labels = test[target_column].values\n","\n","  lexicons = get_lexicons(train, shap_values)\n","  newlexicons = merge_subwords(lexicons, train)\n","  filtered_lexicons = filter_lexicons(newlexicons, q=0.50)  \n","\n","  for c in filtered_lexicons:\n","    filtered_lexicons[c] = {k: v for k, v in sorted(filtered_lexicons[c].items(), key=lambda item: -item[1])}\n","  \n","  with open(f'Results/TaskC/lexicon_shapley_train_{i}.json', 'w') as outfile:\n","      json.dump(filtered_lexicons, outfile)\n","\n","  f1, skip, y_test, y_pred = run_predict(test_words, test_labels, filtered_lexicons, return_predict=True)\n","  p, r, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n","\n","  all_p.append(p)\n","  all_r.append(r)\n","  all_f1.append(f1)\n","  all_skip.append(skip)\n","\n","print(f\"F1:{np.mean(all_f1):.3f}±{np.std(all_f1):.3f}, SKIP: {np.mean(all_skip):.3f}±{np.std(all_skip):.3f}\")\n","print(f\"P:{np.mean(all_p):.3f}±{np.std(all_p):.3f}, R: {np.mean(all_r):.3f}±{np.std(all_r):.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQp2y-1AimJj","executionInfo":{"status":"ok","timestamp":1675386579553,"user_tz":0,"elapsed":46882,"user":{"displayName":"Pakawat Nakwijit","userId":"01430675152978466058"}},"outputId":"100bb5b0-9bfc-4d99-ec93-1fcd5a6a834e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Working on 1.1 threats of harm\n","Working on 1.2 incitement and encouragement of harm\n","Working on 2.1 descriptive attacks\n","Working on 2.2 aggressive and emotive attacks\n","Working on 2.3 dehumanising attacks & overt sexual objectification\n","Working on 3.1 casual use of gendered slurs, profanities, and insults\n","Working on 3.2 immutable gender differences and gender stereotypes\n","Working on 3.3 backhanded gendered compliments\n","Working on 3.4 condescending explanations or unwelcome advice\n","Working on 4.1 supporting mistreatment of individual women\n","Working on 4.2 supporting systemic discrimination against women as a group\n"]},{"output_type":"stream","name":"stderr","text":["Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"output_type":"stream","name":"stdout","text":["Working on 1.1 threats of harm\n","Working on 1.2 incitement and encouragement of harm\n","Working on 2.1 descriptive attacks\n","Working on 2.2 aggressive and emotive attacks\n","Working on 2.3 dehumanising attacks & overt sexual objectification\n","Working on 3.1 casual use of gendered slurs, profanities, and insults\n","Working on 3.2 immutable gender differences and gender stereotypes\n","Working on 3.3 backhanded gendered compliments\n","Working on 3.4 condescending explanations or unwelcome advice\n","Working on 4.1 supporting mistreatment of individual women\n","Working on 4.2 supporting systemic discrimination against women as a group\n"]},{"output_type":"stream","name":"stderr","text":["Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"output_type":"stream","name":"stdout","text":["Working on 1.1 threats of harm\n","Working on 1.2 incitement and encouragement of harm\n","Working on 2.1 descriptive attacks\n","Working on 2.2 aggressive and emotive attacks\n","Working on 2.3 dehumanising attacks & overt sexual objectification\n","Working on 3.1 casual use of gendered slurs, profanities, and insults\n","Working on 3.2 immutable gender differences and gender stereotypes\n","Working on 3.3 backhanded gendered compliments\n","Working on 3.4 condescending explanations or unwelcome advice\n","Working on 4.1 supporting mistreatment of individual women\n","Working on 4.2 supporting systemic discrimination against women as a group\n"]},{"output_type":"stream","name":"stderr","text":["Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"output_type":"stream","name":"stdout","text":["Working on 1.1 threats of harm\n","Working on 1.2 incitement and encouragement of harm\n","Working on 2.1 descriptive attacks\n","Working on 2.2 aggressive and emotive attacks\n","Working on 2.3 dehumanising attacks & overt sexual objectification\n","Working on 3.1 casual use of gendered slurs, profanities, and insults\n","Working on 3.2 immutable gender differences and gender stereotypes\n","Working on 3.3 backhanded gendered compliments\n","Working on 3.4 condescending explanations or unwelcome advice\n","Working on 4.1 supporting mistreatment of individual women\n","Working on 4.2 supporting systemic discrimination against women as a group\n"]},{"output_type":"stream","name":"stderr","text":["Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"output_type":"stream","name":"stdout","text":["Working on 1.1 threats of harm\n","Working on 1.2 incitement and encouragement of harm\n","Working on 2.1 descriptive attacks\n","Working on 2.2 aggressive and emotive attacks\n","Working on 2.3 dehumanising attacks & overt sexual objectification\n","Working on 3.1 casual use of gendered slurs, profanities, and insults\n","Working on 3.2 immutable gender differences and gender stereotypes\n","Working on 3.3 backhanded gendered compliments\n","Working on 3.4 condescending explanations or unwelcome advice\n","Working on 4.1 supporting mistreatment of individual women\n","Working on 4.2 supporting systemic discrimination against women as a group\n","F1:0.120±0.010, SKIP: 0.000±0.000\n","P:0.154±0.020, R: 0.140±0.024\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"VAjHcEP1oXpC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MpZfR7daowME"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WT_yeDLMowOp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = pd.read_csv(\"../Data/starting_ki/train_all_tasks.csv\")\n","train = train[train[target_column]!=\"none\"]\n","\n","lexicons = get_lexicons(train, shap_values)\n","newlexicons = merge_subwords(lexicons, train)\n","filtered_lexicons = filter_lexicons(newlexicons, q=0.50)  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q2oWfJecowRh","executionInfo":{"status":"ok","timestamp":1675386589785,"user_tz":0,"elapsed":10253,"user":{"displayName":"Pakawat Nakwijit","userId":"01430675152978466058"}},"outputId":"417fffd4-e52f-4bb4-acba-3d5525fd7e35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"output_type":"stream","name":"stdout","text":["Working on 1.1 threats of harm\n","Working on 1.2 incitement and encouragement of harm\n","Working on 2.1 descriptive attacks\n","Working on 2.2 aggressive and emotive attacks\n","Working on 2.3 dehumanising attacks & overt sexual objectification\n","Working on 3.1 casual use of gendered slurs, profanities, and insults\n","Working on 3.2 immutable gender differences and gender stereotypes\n","Working on 3.3 backhanded gendered compliments\n","Working on 3.4 condescending explanations or unwelcome advice\n","Working on 4.1 supporting mistreatment of individual women\n","Working on 4.2 supporting systemic discrimination against women as a group\n"]}]},{"cell_type":"code","source":["for c in filtered_lexicons:\n","  filtered_lexicons[c] = {k: v for k, v in sorted(filtered_lexicons[c].items(), key=lambda item: -item[1])}\n","\n","  print(c, list(filtered_lexicons[c].keys())[0:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ZgnTo9powUd","executionInfo":{"status":"ok","timestamp":1675386589786,"user_tz":0,"elapsed":14,"user":{"displayName":"Pakawat Nakwijit","userId":"01430675152978466058"}},"outputId":"56600f87-4d82-4e9c-d297-fb895c15ac9d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1.1 threats of harm ['whore', 'bitches', 'bitch', 'poppy', 'pussy', 'slutshamed', 'women', 'needs', 'slap', 'sexiest']\n","1.2 incitement and encouragement of harm ['whores', 'skank', 'whore', 'pussies', 'bitches', 'bitch', 'pussy', 'hahaha', 'feminism', 'ww3']\n","2.1 descriptive attacks ['skank', 'pussies', 'foids', 'femsplaining', 'pussyhats', 'bitches', 'pussypassdenied', 'bitchy', 'bhahahahahaahahahahaha', 'bitch']\n","2.2 aggressive and emotive attacks ['hillaryclintonisabitch', 'noodlewhore', 'sl00ts', 'bitches', \"bitch's\", 'bitchy', 'libtards', 'bitch', 'hooker', 'disloyal']\n","2.3 dehumanising attacks & overt sexual objectification ['noodlefoids', 'pussies', 'fembots', 'femoids', 'pussypass', 'hooker', 'femoid', 'bitches', 'pussy', 'bitch']\n","3.1 casual use of gendered slurs, profanities, and insults ['muhahahahahahahahahahahahahahahaha', 'pussyfooting', 'bitchtard', 'bitchboi', 'bitches', 'autothots', 'bitching', 'npcunt', 'bitchy', 'cuntfused']\n","3.2 immutable gender differences and gender stereotypes ['bitchy', 'bitches', 'bitch', 'daughters', 'gymmaxxed', 'hooker', 'perfect', 'slut', 'moms', 'babe']\n","3.3 backhanded gendered compliments ['bitch', 'dyke', 'pussies', 'slut', 'pussy', 'femininity', 'females', 'miniskirts', 'sensible', 'blonde']\n","3.4 condescending explanations or unwelcome advice ['girls', 'pussy', 'ladies', 'thot', 'wifey', 'mansplain', 'anecdotes', 'bitch', 'mom', 'hymen']\n","4.1 supporting mistreatment of individual women ['feminazi', 'whorellywood', 'trumpaccusers', 'pussy', 'whore', 'pussies', 'hooker', 'feminists', 'hypocrisy', 'feminist']\n","4.2 supporting systemic discrimination against women as a group ['bitch', 'chicks', 'pussypass', 'pussy', 'femoid', 'mothers', 'feminazis', 'feminazi', 'homosexuals', 'femaleprivilege']\n"]}]},{"cell_type":"code","source":["import json\n","with open('Results/TaskC/lexicon_shapley.json', 'w') as outfile:\n","    json.dump(filtered_lexicons, outfile)"],"metadata":{"id":"jzOht-tNpa55"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NQlkT2WxowZ4"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}